The notebooks implement an end-to-end fine-tuning workflow covering data preparation, model training with LoRA adapters, and post-training evaluation.

Key Concepts
- Parameter-Efficient Fine-Tuning (PEFT)  
- LoRA adapters and layer freezing  
- Instructionâ€“response dataset design  
- Quantitative and qualitative evaluation
